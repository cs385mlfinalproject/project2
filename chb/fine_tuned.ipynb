{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "data loading finished!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(20)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "# import data_reader\n",
    "# trainloader, testloader = data_reader.data_loader()\n",
    "\n",
    "dataloaders_dict = {'train': trainloader, 'val':testloader}\n",
    "print('data loading finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(trainset[0][0].shape)\n",
    "# # print(dir(torchvision.datasets))\n",
    "# voc_trainset = torchvision.datasets.VOCSegmentation('./data/voc_dataset', year='2012', image_set='train', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(voc_trainset[0][0])\n",
    "# print(voc_trainset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    " \n",
    "model_name = 'resnet50' # 'vgg16'   \n",
    "num_classes = 10\n",
    "\n",
    "if model_name.lower() == 'vgg16':\n",
    "    model_ft = models.vgg16(pretrained=True)\n",
    "elif model_name.lower() == 'alexnet':\n",
    "    model_ft = models.alexnet(pretrained=True)\n",
    "elif model_name.lower() == 'resnet50':\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if model_name.lower() == 'vgg16' or model_name == 'alexnet':\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "elif model_name.lower() == 'resnet50':\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "else:\n",
    "    raise ValueError\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ft = model_ft.to(device)\n",
    "params_to_update = model_ft.parameters()\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.003, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_of_coarse=3, num_epochs=10, is_resnet=False):\n",
    "    since = time.time()\n",
    "\n",
    "    train_val_history = []\n",
    "    \n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_val = {}\n",
    "        \n",
    "        if epoch >= num_of_coarse and not is_resnet:\n",
    "            for param in model_ft.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            train_val[phase] = (epoch_loss, epoch_acc)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             if phase == 'val':\n",
    "#                 val_acc_history.append(epoch_acc)\n",
    "        \n",
    "        train_val_history.append(train_val)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_val_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "train Loss: 0.8883 Acc: 0.7272\n",
      "val Loss: 0.6513 Acc: 0.7878\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "train Loss: 0.6259 Acc: 0.7905\n",
      "val Loss: 0.5944 Acc: 0.8038\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "train Loss: 0.5828 Acc: 0.8020\n",
      "val Loss: 0.5730 Acc: 0.8053\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 0.8080\n",
      "val Loss: 0.5532 Acc: 0.8083\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "train Loss: 0.5466 Acc: 0.8133\n",
      "val Loss: 0.5503 Acc: 0.8106\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "train Loss: 0.5355 Acc: 0.8151\n",
      "val Loss: 0.5414 Acc: 0.8123\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "train Loss: 0.5270 Acc: 0.8178\n",
      "val Loss: 0.5334 Acc: 0.8188\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "train Loss: 0.5195 Acc: 0.8195\n",
      "val Loss: 0.5343 Acc: 0.8145\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "train Loss: 0.5108 Acc: 0.8228\n",
      "val Loss: 0.5258 Acc: 0.8207\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "train Loss: 0.5081 Acc: 0.8228\n",
      "val Loss: 0.5316 Acc: 0.8172\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "train Loss: 0.5029 Acc: 0.8266\n",
      "val Loss: 0.5287 Acc: 0.8184\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "train Loss: 0.4958 Acc: 0.8278\n",
      "val Loss: 0.5156 Acc: 0.8215\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "train Loss: 0.4924 Acc: 0.8294\n",
      "val Loss: 0.5125 Acc: 0.8242\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "train Loss: 0.4896 Acc: 0.8298\n",
      "val Loss: 0.5124 Acc: 0.8241\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "train Loss: 0.4873 Acc: 0.8304\n",
      "val Loss: 0.5175 Acc: 0.8214\n",
      "\n",
      "Training complete in 26m 9s\n",
      "Best val Acc: 0.824200\n"
     ]
    }
   ],
   "source": [
    "model_ft, history = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, 6, 15, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'data/models/{}_v1.model'.format(model_name))\n",
    "with open('data/trainHistory/{}_history_v1.pkl'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = data_reader.get_data_array('cifar-10', 'data/cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "img = train_X[120] \n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8wuRKXJ+ITJFzi9Epsj5hciU/wdCBlieMAeItQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = train_X[120]\n",
    "% matplotlib inline\n",
    "plt.figure('cam')\n",
    "plt.imshow(img / 255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
